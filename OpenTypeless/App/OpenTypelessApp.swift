import SwiftUI
import AVFoundation
import ApplicationServices
import Speech

@main
struct OpenTypelessApp: App {
    @NSApplicationDelegateAdaptor(AppDelegate.self) var appDelegate

    var body: some Scene {
        Settings {
            SettingsView()
        }
    }
}

class AppDelegate: NSObject, NSApplicationDelegate {
    private var statusItem: NSStatusItem!
    private var popover: NSPopover!

    // Managers
    private let hotkeyManager = HotkeyManager.shared
    private let floatingPanel = FloatingPanelController.shared
    private var speechProvider: (any SpeechRecognitionProvider)?
    private var aiProvider: AzureOpenAIProvider?

    func applicationDidFinishLaunching(_ notification: Notification) {
        print("========================================")
        print("[App] OpenTypeless starting...")
        print("========================================")

        setupMenuBar()
        requestPermissions()
        setupHotkeys()
        setupSpeechRecognition()

        print("[App] âœ… App initialization complete")
        print("========================================")
    }

    func applicationWillTerminate(_ notification: Notification) {
        print("[App] Shutting down...")
        hotkeyManager.stopMonitoring()
    }

    // MARK: - Menu Bar Setup

    private func setupMenuBar() {
        print("[App] Setting up menu bar...")

        statusItem = NSStatusBar.system.statusItem(withLength: NSStatusItem.variableLength)

        if let button = statusItem.button {
            // Use custom Westie dog icon
            if let image = NSImage(named: "MenuBarIcon") {
                image.isTemplate = true
                image.size = NSSize(width: 18, height: 18)
                button.image = image
            } else {
                // Fallback to SF Symbol if custom icon not found
                button.image = NSImage(systemSymbolName: "mic.fill", accessibilityDescription: "OpenTypeless")
            }
            button.action = #selector(togglePopover)
            print("[App] âœ… Menu bar icon created")
        }

        popover = NSPopover()
        popover.contentSize = NSSize(width: 320, height: 400)
        popover.behavior = .transient
        popover.contentViewController = NSHostingController(rootView: MenuBarView())

        print("[App] âœ… Menu bar setup complete")
    }

    @objc private func togglePopover() {
        guard let button = statusItem.button else { return }

        if popover.isShown {
            popover.performClose(nil)
        } else {
            popover.show(relativeTo: button.bounds, of: button, preferredEdge: .minY)
            popover.contentViewController?.view.window?.makeKey()
        }
    }

    // MARK: - Permissions

    private func requestPermissions() {
        print("[App] Checking permissions...")

        // Request microphone permission
        print("[App] Requesting microphone permission...")
        AVCaptureDevice.requestAccess(for: .audio) { granted in
            print("[App] Microphone permission: \(granted ? "âœ… granted" : "âŒ denied")")
        }

        // Request speech recognition permission
        print("[App] Requesting speech recognition permission...")
        SFSpeechRecognizer.requestAuthorization { status in
            let statusStr: String
            switch status {
            case .authorized: statusStr = "âœ… authorized"
            case .denied: statusStr = "âŒ denied"
            case .restricted: statusStr = "âš ï¸ restricted"
            case .notDetermined: statusStr = "â³ not determined"
            @unknown default: statusStr = "â“ unknown"
            }
            print("[App] Speech recognition permission: \(statusStr)")
        }

        // Check accessibility permission
        print("[App] Checking accessibility permission...")
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            let options = [kAXTrustedCheckOptionPrompt.takeUnretainedValue() as String: true]
            let accessibilityEnabled = AXIsProcessTrustedWithOptions(options as CFDictionary)
            print("[App] Accessibility permission: \(accessibilityEnabled ? "âœ… granted" : "âŒ denied")")

            if !accessibilityEnabled {
                print("[App] âš ï¸ Accessibility permission required for text insertion.")
                print("[App]    Please go to: System Settings â†’ Privacy & Security â†’ Accessibility")
                print("[App]    Then add this app or Xcode (if running from Xcode)")
            }
        }
    }

    // MARK: - Hotkey Setup

    private func setupHotkeys() {
        print("[App] Setting up hotkeys...")

        hotkeyManager.onFnKeyDown = { [weak self] in
            print("[App] ğŸ¤ fn key pressed - starting voice input")
            self?.startVoiceInput()
        }

        hotkeyManager.onFnKeyUp = { [weak self] in
            print("[App] ğŸ›‘ fn key released - stopping voice input")
            self?.stopVoiceInput()
        }

        hotkeyManager.startMonitoring()
        print("[App] âœ… Hotkey setup complete - Press and hold fn key to start voice input")
    }

    // MARK: - Speech Recognition Setup

    private func setupSpeechRecognition() {
        print("[App] Setting up speech recognition...")

        // Get selected provider from settings
        let selectedProvider = UserDefaults.standard.string(forKey: "speechProvider") ?? "apple"
        print("[App] Selected speech provider: \(selectedProvider)")

        switch selectedProvider {
        case "azure":
            print("[App] Using Azure Speech Service")
            let azureProvider = AzureSpeechProvider()
            if azureProvider.isAvailable {
                speechProvider = azureProvider
            } else {
                print("[App] âš ï¸ Azure Speech not configured, falling back to Apple Speech")
                speechProvider = AppleSpeechProvider()
            }
        case "whisper":
            print("[App] Whisper API not implemented yet, using Apple Speech")
            speechProvider = AppleSpeechProvider()
        case "local-whisper":
            print("[App] Local Whisper not implemented yet, using Apple Speech")
            speechProvider = AppleSpeechProvider()
        default:
            print("[App] Using Apple Speech Framework")
            speechProvider = AppleSpeechProvider()
        }

        speechProvider?.onPartialResult { [weak self] result in
            print("[App] Partial result: \(result.text)")
            self?.floatingPanel.updateTranscription(result.text)
        }

        speechProvider?.onError { error in
            print("[App] âŒ Speech recognition error: \(error.localizedDescription)")
        }

        // Setup AI provider
        aiProvider = AzureOpenAIProvider()
        let aiEnabled = UserDefaults.standard.bool(forKey: "aiPolishEnabled")
        print("[App] AI polish: \(aiEnabled ? "enabled" : "disabled")")

        print("[App] âœ… Speech recognition setup complete")
        print("[App] Active provider: \(speechProvider?.name ?? "unknown")")
    }

    // MARK: - Voice Input

    private func startVoiceInput() {
        print("[App] Starting voice input...")

        // Update menu bar icon (tint red when recording)
        DispatchQueue.main.async {
            if let image = NSImage(named: "MenuBarIcon") {
                image.isTemplate = true
                image.size = NSSize(width: 18, height: 18)
                self.statusItem.button?.image = image
            }
            self.statusItem.button?.contentTintColor = .red
        }

        // Show floating panel
        floatingPanel.showPanel()

        // Start speech recognition
        Task {
            do {
                let language = UserDefaults.standard.string(forKey: "speechLanguage") ?? "zh-CN"
                print("[App] Starting recognition with language: \(language)")
                try await speechProvider?.startRecognition(language: language)
                print("[App] âœ… Speech recognition started")
            } catch {
                print("[App] âŒ Failed to start speech recognition: \(error)")
                floatingPanel.showError(error.localizedDescription)
            }
        }
    }

    private func stopVoiceInput() {
        print("[App] Stopping voice input...")

        // Reset menu bar icon
        DispatchQueue.main.async {
            if let image = NSImage(named: "MenuBarIcon") {
                image.isTemplate = true
                image.size = NSSize(width: 18, height: 18)
                self.statusItem.button?.image = image
            }
            self.statusItem.button?.contentTintColor = nil
        }

        // Stop speech recognition and get result
        Task {
            do {
                var result = try await speechProvider?.stopRecognition() ?? ""
                print("[App] âœ… Final transcription: \(result)")

                if result.isEmpty {
                    print("[App] âš ï¸ No transcription result")
                    floatingPanel.hidePanel()
                    return
                }

                // Check if AI polish is enabled
                let aiEnabled = UserDefaults.standard.bool(forKey: "aiPolishEnabled")

                if aiEnabled {
                    print("[App] ğŸ¤– AI polish enabled, processing...")
                    floatingPanel.updateTranscription("æ­£åœ¨æ¶¦è‰²: \(result)")

                    // Reload AI provider config
                    aiProvider?.reloadConfig()

                    if let aiProvider = aiProvider, aiProvider.isAvailable {
                        // Get system prompt, use default if empty
                        var systemPrompt = UserDefaults.standard.string(forKey: "aiSystemPrompt") ?? ""
                        if systemPrompt.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
                            systemPrompt = """
ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³è½¬æ–‡å­—çš„åå¤„ç†å·¥å…·ã€‚ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯ä¿®æ­£å’Œæ¶¦è‰²è¯­éŸ³è¯†åˆ«çš„åŸå§‹è¾“å‡ºã€‚

è§„åˆ™ï¼š
1. ä¿®æ­£é”™åˆ«å­—å’Œè¯­éŸ³è¯†åˆ«é”™è¯¯
2. æ·»åŠ å¿…è¦çš„æ ‡ç‚¹ç¬¦å·ï¼Œæ¢è¡Œï¼Œåˆ†æ¡åˆ—ç‚¹ã€‚
3. ä¸è¦å›å¤ã€ä¸è¦å¯¹è¯ã€ä¸è¦è§£é‡Š
4. åˆ é™¤æ— æ•ˆå’Œé‡å¤çš„è¯ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹
5. ç›´æ¥è¾“å‡ºä¿®æ­£åçš„åŸæ–‡ï¼Œæ— ä»»ä½•å‰ç¼€
6. ä¸è¾“å…¥ä¿æŒç›¸åŒçš„è¯­è¨€ã€‚

ç¤ºä¾‹ï¼š
è¾“å…¥ï¼šä½ å¥½ï¼Œä½ å¥½ï¼Œé‚£ä»€ä¹ˆä»Šå¤©ä½ åƒé¥­äº†æ²¡
è¾“å‡ºï¼šä½ å¥½ï¼Œä»Šå¤©ä½ åƒé¥­äº†æ²¡ï¼Ÿ

è¾“å…¥ï¼šä½ ä»Šå¤©è®°å¾—å¹²ä¸¤ä»¶äº‹ï¼Œä¸€ä»¶æ˜¯å»è¶…å¸‚ä¹°èœï¼Œå¦ä¸€ä¸ªæ˜¯å»ç»ƒä¹ æ‰“çƒ
è¾“å‡ºï¼šä½ ä»Šå¤©è®°å¾—å¹²ä¸¤ä»¶äº‹
1. å»è¶…å¸‚ä¹°èœ
2. ç»ƒä¹ æ‰“çƒ

è¾“å…¥ï¼šGPTçº¹èº«å›¾æ¨¡å‹
è¾“å‡ºï¼šGPTæ–‡ç”Ÿå›¾æ¨¡å‹
"""
                            print("[App] Using default system prompt (saved prompt was empty)")
                        }

                        do {
                            let polishedText = try await aiProvider.polish(text: result, systemPrompt: systemPrompt)
                            print("[App] âœ… AI polished: \(polishedText)")
                            result = polishedText
                        } catch {
                            print("[App] âŒ AI polish failed: \(error)")
                            // Continue with original text if AI fails
                        }
                    } else {
                        print("[App] âš ï¸ AI provider not configured, using original text")
                    }
                }

                floatingPanel.showResult(result)
                // Insert text at cursor position
                await insertText(result)

            } catch {
                print("[App] âŒ Failed to stop speech recognition: \(error)")
                floatingPanel.showError(error.localizedDescription)
            }
        }
    }

    // MARK: - Text Insertion

    @MainActor
    private func insertText(_ text: String) async {
        print("[App] Inserting text: \(text)")

        // Check accessibility permission
        guard AXIsProcessTrusted() else {
            print("[App] âŒ Cannot insert text - accessibility permission not granted")
            return
        }

        // Use keyboard simulation to insert text
        print("[App] Simulating keyboard input...")

        // Copy text to clipboard
        let pasteboard = NSPasteboard.general
        pasteboard.clearContents()
        pasteboard.setString(text, forType: .string)

        // Simulate Cmd+V to paste
        let source = CGEventSource(stateID: .hidSystemState)

        // Key down: Cmd+V
        let keyDown = CGEvent(keyboardEventSource: source, virtualKey: 0x09, keyDown: true) // V key
        keyDown?.flags = .maskCommand
        keyDown?.post(tap: .cghidEventTap)

        // Key up: Cmd+V
        let keyUp = CGEvent(keyboardEventSource: source, virtualKey: 0x09, keyDown: false)
        keyUp?.flags = .maskCommand
        keyUp?.post(tap: .cghidEventTap)

        print("[App] âœ… Text inserted via clipboard paste")
    }
}
